{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create multi-model ensembles (MME)\n",
    "1. Equally weighted ensemble (same weight to each quantile).\n",
    "2. MME using the degenerate EM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir   = config.get_property('results_dir')\n",
    "data_dir      = config.get_property('data_dir')\n",
    "\n",
    "def create_df_ensemble(weights_df, forecast_df_list, name_models):\n",
    "    e_df = [forecast_df_list[idx]* weights_df.loc[name_models[idx]][\"weigth\"] for idx in range(len(forecast_df_list))]\n",
    "    e_df = sum(e_df)\n",
    "    return e_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_frcst_1 = os.path.join(results_dir, \"forecast\", \"arima\")\n",
    "path_to_frcst_2 = os.path.join(results_dir, \"forecast\", \"eakf_model1\")\n",
    "path_to_frcst_3 = os.path.join(results_dir, \"forecast\", \"eakf_model2\")\n",
    "path_to_frcst_4 = os.path.join(results_dir, \"forecast\", \"eakf_model3\")\n",
    "\n",
    "data_df         = pd.read_csv(os.path.join(data_dir, \"processed_data_us.csv\"), parse_dates=[\"date\"])\n",
    "dates_forecasts = data_df.date[11:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_frcst import degenerate_em_weights\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equally weighted ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx_date, date_use in enumerate(dates_forecasts):\n",
    "\n",
    "    past_scores  = -1 # window size, not used here.\n",
    "    #date_use_idx = 6\n",
    "\n",
    "    prev_dates  = pd.to_datetime(dates_forecasts[:idx_date])\n",
    "    date_str    = pd.to_datetime(date_use).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    frcst1_df   = pd.read_csv(os.path.join(path_to_frcst_1, f\"{date_str}.csv\"), parse_dates=[\"date\", \"forecast_date\"]).drop(columns=[\"forecast_date\"]).set_index([\"date\"]).iloc[:6]\n",
    "    frcst2_df   = pd.read_csv(os.path.join(path_to_frcst_2, f\"{date_str}.csv\"), parse_dates=[\"date\", \"forecast_date\"]).drop(columns=[\"Unnamed: 0\", \"type\", \"std\", \"forecast_date\"]).set_index([\"date\"]).iloc[:6]\n",
    "    frcst3_df   = pd.read_csv(os.path.join(path_to_frcst_3, f\"{date_str}.csv\"), parse_dates=[\"date\", \"forecast_date\"]).drop(columns=[\"Unnamed: 0\", \"type\", \"std\", \"forecast_date\"]).set_index([\"date\"]).iloc[:6]\n",
    "    frcst4_df   = pd.read_csv(os.path.join(path_to_frcst_4, f\"{date_str}.csv\"), parse_dates=[\"date\", \"forecast_date\"]).drop(columns=[\"Unnamed: 0\", \"type\", \"std\", \"forecast_date\"]).set_index([\"date\"]).iloc[:6]\n",
    "\n",
    "    f_list       = [frcst1_df, frcst2_df, frcst3_df, frcst4_df]\n",
    "    name_models  = ['arima', 'eakf_model1', 'eakf_model2', \"eakf_model3\"]\n",
    "    w_df         = degenerate_em_weights(np.array([[1, 1, 1, 1]])/4, models_name=name_models)\n",
    "    ens_df       = create_df_ensemble(w_df, f_list, name_models)\n",
    "\n",
    "    path_to_save_ens = os.path.join(results_dir, \"forecast\", \"ensemble\", \"equal_weights\")\n",
    "    ens_df.to_csv((os.path.join(path_to_save_ens,  f\"{date_str}.csv\")))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MME using the EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = pd.read_csv(os.path.join(results_dir, \"forecast\", \"evaluation\", \"forecasts.csv\"), parse_dates=[\"forecast_date\"]).dropna(axis=1)\n",
    "evals_df     = pd.read_csv(os.path.join(results_dir, \"forecast\", \"evaluation\", \"scores.csv\"), parse_dates=[\"frsct_date\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use all past performance data to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_windows = {\"1m\": 1, \"2m\": 2, \"3m\": 3, \"4m\": 4, \"5m\": 5, \"6m\": 6}\n",
    "scores    = [\"wis\"]\n",
    "dates_use = dates_forecasts[6:]\n",
    "\n",
    "for idx_date_use, date_use in enumerate(dates_use):\n",
    "    for fw in list(list(forecast_windows.keys())):\n",
    "\n",
    "        fw_int = int(fw[0])-1\n",
    "\n",
    "        past_scores  = -1 # window size, not used here.\n",
    "        date_use_idx = 6+idx_date_use\n",
    "\n",
    "        prev_dates  = pd.to_datetime(dates_forecasts[:date_use_idx-fw_int])\n",
    "        date_str    = pd.to_datetime(date_use).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        f_date_df      = forecasts_df[forecasts_df[\"forecast_date\"] == date_str]\n",
    "        forecast1_df   = f_date_df[f_date_df.model == 'arima'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\" , \"forecast_date\"])\n",
    "        forecast2_df   = f_date_df[f_date_df.model == 'model1'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\", \"forecast_date\"])\n",
    "        forecast3_df   = f_date_df[f_date_df.model == 'model2'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\", \"forecast_date\"])\n",
    "        forecast4_df   = f_date_df[f_date_df.model == 'model3'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\", \"forecast_date\"])\n",
    "\n",
    "        # put forecasts in a list\n",
    "        f_list       = [forecast1_df, forecast2_df, forecast3_df, forecast4_df]\n",
    "\n",
    "        evals_use_df = evals_df[evals_df.frsct_date.isin(prev_dates)]\n",
    "        evals_use_df = evals_use_df[evals_use_df.eval_horizon==fw]\n",
    "\n",
    "        eval_ma_df   = pd.pivot(evals_use_df, index=\"frsct_date\", columns=\"method\", values=\"wis\")\n",
    "        name_models  = list(eval_ma_df.keys())\n",
    "\n",
    "        normalize_score = 1 - eval_ma_df.to_numpy()/np.linalg.norm(eval_ma_df.to_numpy(), axis=1, keepdims=True)\n",
    "\n",
    "        w_df            = degenerate_em_weights(normalize_score, models_name=name_models)\n",
    "        ens_df          = create_df_ensemble(w_df, f_list, name_models)\n",
    "\n",
    "        path_to_save_ens = os.path.join(results_dir, \"forecast\", \"ensemble\", \"all_past\", f\"wis\", fw)\n",
    "        path_to_save_w   = os.path.join(pasth_to_save_ens, \"weights\")\n",
    "\n",
    "        os.makedirs(path_to_save_ens, exist_ok=True)\n",
    "        os.makedirs(path_to_save_w, exist_ok=True)\n",
    "\n",
    "        w_df.to_csv(os.path.join(path_to_save_w,  f\"{date_str}.csv\"))\n",
    "        ens_df.to_csv((os.path.join(path_to_save_ens,  f\"{date_str}.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_windows = {\"1m\": 1, \"2m\": 2, \"3m\": 3, \"4m\": 4, \"5m\": 5, \"6m\": 6}\n",
    "scores = [\"wis\"]\n",
    "dates_use = dates_forecasts[6:]\n",
    "\n",
    "weights_df = []\n",
    "for idx_date_use, date_use in enumerate(dates_use):\n",
    "    date_str    = pd.to_datetime(date_use).strftime(\"%Y-%m-%d\")\n",
    "    for fw in list(list(forecast_windows.keys())):\n",
    "\n",
    "        path_to_save_ens = os.path.join(results_dir, \"forecast\", \"ensemble\", \"all_past\", f\"wis\", fw)\n",
    "        path_to_save_w   = os.path.join(path_to_save_ens, \"weights\")\n",
    "\n",
    "        w_df                   = pd.read_csv(os.path.join(path_to_save_w,  f\"{date_str}.csv\"))\n",
    "        w_df[\"date_forecast\"] = date_str\n",
    "        w_df[\"forecast_window\"] = fw\n",
    "        weights_df.append(w_df)\n",
    "\n",
    "weights_df = pd.concat(weights_df)\n",
    "weights_df.to_csv(os.path.join(results_dir, \"forecast\", \"evaluation\", \"weights_AllPast.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use k-months past performance data to train the model\n",
    "We used k from 2 to 6 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_windows = {\"1m\": 1, \"2m\": 2, \"3m\": 3, \"4m\": 4, \"5m\": 5, \"6m\": 6}\n",
    "score_use_to_ensemble = \"wis\"\n",
    "\n",
    "dates_use       = dates_forecasts[6:]\n",
    "past_points_use = [2, 3, 4, 5, 6]\n",
    "\n",
    "for K in past_points_use:\n",
    "    for idx_date_use, date_use in enumerate(dates_use):\n",
    "        for fw in list(list(forecast_windows.keys())):\n",
    "\n",
    "            fw_int = int(fw[0])-1\n",
    "\n",
    "            past_scores  = -1 # window size, not used here.\n",
    "            date_use_idx = 6+idx_date_use\n",
    "            date_str    = pd.to_datetime(date_use).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            prev_dates  = pd.to_datetime(dates_forecasts[date_use_idx-fw_int-K:date_use_idx-fw_int])\n",
    "            if len(prev_dates)==0:\n",
    "                continue\n",
    "\n",
    "            #print(prev_dates)\n",
    "            f_date_df      = forecasts_df[forecasts_df[\"forecast_date\"] == date_str]\n",
    "            forecast1_df   = f_date_df[f_date_df.model == 'arima'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\", \"forecast_date\"])\n",
    "            forecast2_df   = f_date_df[f_date_df.model == 'model1'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\", \"forecast_date\"])\n",
    "            forecast3_df   = f_date_df[f_date_df.model == 'model2'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\", \"forecast_date\"])\n",
    "            forecast4_df   = f_date_df[f_date_df.model == 'model3'].iloc[:6].set_index([\"date\"]).drop(columns=[\"add\", \"model\", \"forecast_date\"])\n",
    "\n",
    "            f_list       = [forecast1_df, forecast2_df, forecast3_df, forecast4_df]\n",
    "\n",
    "            evals_use_df = evals_df[evals_df.frsct_date.isin(pd.to_datetime(prev_dates))]\n",
    "            evals_use_df = evals_use_df[evals_use_df.eval_horizon==fw]\n",
    "\n",
    "            if len(evals_use_df)==0:\n",
    "                continue\n",
    "\n",
    "            eval_ma_df      = pd.pivot(evals_use_df, index=\"frsct_date\", columns=\"method\", values=score_use_to_ensemble)\n",
    "            name_models     = list(eval_ma_df.keys())\n",
    "\n",
    "            normalize_score = 1 - eval_ma_df.to_numpy()/np.linalg.norm(eval_ma_df.to_numpy(), axis=1, keepdims=True)\n",
    "            w_df            = degenerate_em_weights(normalize_score, models_name=name_models)\n",
    "            ens_df          = create_df_ensemble(w_df, f_list, name_models)\n",
    "\n",
    "            ##### - ##### - ##### - ##### - ##### - ##### - #####\n",
    "            path_to_save_ens = os.path.join(results_dir, \"forecast\", \"ensemble\", f\"{K}_months_past\", fw)\n",
    "            path_to_save_w   = os.path.join(path_to_save_ens, \"weights\")\n",
    "            ##### - ##### - ##### - ##### - ##### - ##### - #####\n",
    "\n",
    "            os.makedirs(path_to_save_ens, exist_ok=True)\n",
    "            os.makedirs(path_to_save_w, exist_ok=True)\n",
    "\n",
    "            w_df.to_csv(os.path.join(path_to_save_w,  f\"{date_str}.csv\"))\n",
    "            ens_df.to_csv((os.path.join(path_to_save_ens,  f\"{date_str}.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
