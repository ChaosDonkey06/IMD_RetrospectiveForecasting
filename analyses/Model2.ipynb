{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from unidecode import unidecode\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pymmwr as pm\n",
    "import urllib\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from global_config import config\n",
    "from itertools import chain\n",
    "\n",
    "results_dir   = config.get_property('results_dir')\n",
    "data_dir      = config.get_property('data_dir')\n",
    "\n",
    "plt.rc('font', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "def compute_oev(obs_vec, var_obs=0.2):\n",
    "    return 1 + (var_obs*obs_vec)**2\n",
    "\n",
    "def checkbound_params(dict_params_range, params_ens, num_ensembles=300):\n",
    "    params_update = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        loww = dict_params_range[p][0]\n",
    "        upp  = dict_params_range[p][1]\n",
    "\n",
    "        p_ens            = params_ens[idx_p, :].copy()\n",
    "\n",
    "        idx_wrong        = np.where(np.logical_or(p_ens <loww, p_ens > upp))[0]\n",
    "        idx_wrong_loww   = np.where(p_ens < loww)[0]\n",
    "        idx_wrong_upp    = np.where(p_ens > upp)[0]\n",
    "        idx_good         = np.where(np.logical_or(p_ens >=loww, p_ens <= upp))[0]\n",
    "        p_ens[idx_wrong] = np.median(p_ens[idx_good])\n",
    "\n",
    "        np.put(p_ens, idx_wrong_loww, loww * (1+0.2*np.random.rand( idx_wrong_loww.shape[0])) )\n",
    "        np.put(p_ens, idx_wrong_upp, upp * (1-0.2*np.random.rand( idx_wrong_upp.shape[0])) )\n",
    "\n",
    "        params_update.append(p_ens)\n",
    "\n",
    "    return np.array(params_update)\n",
    "\n",
    "def checkbound_state_vars(x_state_ens, pop):\n",
    "    loww = 0\n",
    "    upp  = pop\n",
    "    x_state_ens = np.clip(x_state_ens, loww, upp)\n",
    "    return x_state_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df            = pd.read_csv(os.path.join(data_dir, \"processed_data_us.csv\"), parse_dates=[\"date\"])\n",
    "period_analysis_df = pd.read_csv(os.path.join(data_dir, \"period_power.csv\"))\n",
    "best_period        = period_analysis_df.iloc[np.argmax(period_analysis_df.power)][\"period\"] * 12 # Multiply by 12 to convert to months\n",
    "\n",
    "def beta_value(t, amplitude=1, baseline=0, phi=0, gamma=1, period=12):\n",
    "    return np.maximum(gamma*(amplitude/2*np.sin(2*np.pi*(t-phi)/period) + (amplitude/2 + baseline)), 0)\n",
    "\n",
    "beta_sin                  = np.maximum(np.sin(2 * np.pi / best_period * np.arange(len(data_df))), 0)\n",
    "beta_computed_df          = pd.DataFrame(columns=[\"date\", \"beta\"])\n",
    "beta_computed_df[\"date\"]  = data_df[\"date\"]\n",
    "beta_computed_df[\"beta\"]  = beta_sin\n",
    "beta_computed_df[\"beta2\"] = beta_value(np.arange(len(data_df)), baseline=0, phi=-1, period=best_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_transition(var, rate, dt=1, num_ensembles=300):\n",
    "    kb        = np.maximum(1.0 - np.exp(-rate*dt), 0)\n",
    "    num_ind   = np.random.binomial(list(var), kb )\n",
    "    if num_ind.shape[-1]!=num_ensembles:\n",
    "        print(\"Error transitioning stochastic model\")\n",
    "    return np.squeeze(num_ind)\n",
    "\n",
    "######## - ######## - ######## - ########\n",
    "\n",
    "def imd_model(x, betas, omega, theta, N, dt=1):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        x ([type]):           Dimension of [num_state_variables, num_ensembles]\n",
    "        betas ([type]):       Dimension of [num_state_variables, num_ensembles]\n",
    "        pop_pyramid ([type]): Dimension of [num_state_variables, num_ensembles]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    # Infection duration.\n",
    "    gamma   = 1/15\n",
    "\n",
    "    # Carriage duration.\n",
    "    alpha1   = 1/150\n",
    "    alpha2   = 1/10\n",
    "\n",
    "    S       = x[0, :] # Susceptible  [1, num_ensembles]\n",
    "    C       = x[1, :] # Carriers     [1, num_ensembles]\n",
    "    I       = x[2, :] # Infected     [1, num_ensembles]\n",
    "\n",
    "    # Force of Infection\n",
    "    foi =  betas * (C + I + 0) / N\n",
    "\n",
    "    ############ TRANSITIONS ############\n",
    "    s2c   =  binomial_transition(S, dt * foi)                # susceptible to colonized with vaccine preventable strain\n",
    "    c2i   =  binomial_transition(C, dt * alpha2 * theta)      # colonized to infected with vaccine preventable strain\n",
    "    c2s   =  binomial_transition(C, dt * alpha1 * (1-theta))  # colonized to susceptible due to decolonization\n",
    "    i2s   =  binomial_transition(I, dt * gamma)              # infected to susceptible due to infection clearance\n",
    "\n",
    "    S     = S  - s2c  + c2s + i2s\n",
    "    C     = C  + s2c  - c2i - c2s\n",
    "    I     = I  + c2i   - i2s\n",
    "\n",
    "    inc   = c2i\n",
    "\n",
    "    return np.array([S , C , I , inc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "βmin       = 0.002\n",
    "βmax       = 0.006\n",
    "\n",
    "θmin = 0.5e-6\n",
    "θmax = 1.2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_infer import create_df_response, get_truncated_normal, sample_params_uniform, sample_params_normal, eakf_step, checkbound_params\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_ensembles = 300\n",
    "population    = 200e6\n",
    "\n",
    "this_df = data_df.copy()\n",
    "this_df = data_df.copy().set_index(\"date\").resample(\"M\").sum().reset_index()\n",
    "\n",
    "this_df           = this_df.rename(columns={\"total\": \"confirmed\"})\n",
    "this_df[\"oev\"]    = compute_oev(this_df[\"confirmed\"].values)\n",
    "\n",
    "days_simulation       = list(pd.date_range(start=pd.to_datetime(\"2006-01-01\"), end=this_df.iloc[-1][\"date\"]))\n",
    "data_assimilation_df  = this_df.copy().set_index(\"date\")\n",
    "dates_assimilation    = data_assimilation_df.index.values\n",
    "\n",
    "idx_date_update = 0\n",
    "\n",
    "dict_params_range = {}\n",
    "dict_params_range[\"omega\"]             = [βmin, 0.01] #[βmin, βmax]\n",
    "dict_params_range[\"beta_amplitude\"]    = [βmin, βmax] #[(βmax-βmin)/100, (βmax-βmin)/10]\n",
    "dict_params_range[\"theta\"]             = [θmin, θmax]\n",
    "\n",
    "state_params_range       = {}\n",
    "state_params_range[\"S0\"] = [75/100, 95/100]\n",
    "\n",
    "param_prior = sample_params_uniform(dict_params_range, num_ensembles=num_ensembles)\n",
    "\n",
    "obs_t = np.zeros((num_ensembles))\n",
    "\n",
    "num_params    = len(dict_params_range)\n",
    "num_variables = 4\n",
    "\n",
    "num_steps        = len(data_assimilation_df)\n",
    "param_post_time  = np.zeros((num_params, num_ensembles,    num_steps))\n",
    "x_post_time      = np.zeros((num_variables, num_ensembles, num_steps))\n",
    "obs_post_time    = np.zeros((1, num_ensembles, num_steps))\n",
    "\n",
    "\n",
    "idx_date_update  = 0\n",
    "obs_t            = np.zeros((num_ensembles))\n",
    "\n",
    "S0     = np.squeeze(population * sample_params_uniform(state_params_range, num_ensembles=num_ensembles))\n",
    "C0     = np.squeeze((1 - sample_params_uniform(state_params_range, num_ensembles=num_ensembles))*population)\n",
    "I0     = np.zeros(( num_ensembles))\n",
    "\n",
    "inc    = np.zeros(( num_ensembles))\n",
    "x0     = np.array([S0, C0, I0, inc]) # array with initial conditions [num_state_variables, num_age_groups]\n",
    "x      = x0\n",
    "\n",
    "x_prior = np.zeros((num_variables, num_ensembles))\n",
    "\n",
    "for idx_date, date in tqdm(enumerate(dates_assimilation)):\n",
    "        betas_forcing = beta_computed_df.beta\n",
    "\n",
    "        ω                  = param_prior[0, :].copy()\n",
    "        betas_amplitude    = param_prior[1, :].copy()\n",
    "\n",
    "        betas = beta_value(idx_date, amplitude=betas_amplitude, baseline=ω, phi=-1, period=best_period)\n",
    "        betas = np.squeeze(checkbound_params({'b': dict_params_range[\"beta_amplitude\"]}, np.expand_dims(betas, 0), num_ensembles=300))\n",
    "\n",
    "        thetas             = param_prior[2, :].copy()\n",
    "\n",
    "        x_prior = imd_model(x, betas, 0, thetas, N=population, dt=30)\n",
    "        x       = x_prior.copy()\n",
    "        obs     = x[-1,:]\n",
    "        obs_t   += obs\n",
    "\n",
    "        # Since the age groups are an index, the arrangement of the age groups remains.\n",
    "        oev_confirmed_time = data_assimilation_df.loc[date][\"oev\"]\n",
    "        confirmed_time     = data_assimilation_df.loc[date][\"confirmed\"]\n",
    "\n",
    "        x_post, param_post, obs_post = eakf_step(x_prior, param_prior, obs_t, confirmed_time, oev_confirmed_time, dict_params_range, num_var=4)\n",
    "        S       = x_post[0, :] # Susceptible  [1, num_ensembles]\n",
    "        C       = x_post[1, :] # Carriers     [1, num_ensembles]\n",
    "        I       = x_post[2, :] # Infected     [1, num_ensembles]\n",
    "        x_post[0, :] = population*np.ones(S.shape) - C - I # re-adjust susceptibility\n",
    "\n",
    "        x_post                       = checkbound_state_vars(x_post, population)\n",
    "        param_post                   = checkbound_params(dict_params_range, param_post, num_ensembles=300)\n",
    "\n",
    "        x = x_post.copy()\n",
    "\n",
    "        # Use posterior and next prior\n",
    "        param_prior  = param_post.copy()\n",
    "\n",
    "        obs_post_time[:,:,idx_date_update]      = obs_post\n",
    "        param_post_time[:,:,idx_date_update]    = param_prior\n",
    "        x_post_time[:,:,idx_date_update]        = x_post\n",
    "\n",
    "        idx_date_update += 1\n",
    "\n",
    "        obs_t           = np.zeros((num_ensembles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "S_post   = x_post_time[0, :]; S_df = create_df_response(S_post, time= num_steps).reset_index();   S_df[\"date\"] = dates_assimilation\n",
    "C_post   = x_post_time[1, :]; C_df = create_df_response(C_post, time= num_steps).reset_index();   C_df[\"date\"] = dates_assimilation\n",
    "I_post   = x_post_time[2, :]; I_df = create_df_response(I_post, time= num_steps).reset_index();   I_df[\"date\"] = dates_assimilation\n",
    "inc_post = x_post_time[3, :]; inc_df = create_df_response(inc_post, time= num_steps).reset_index(); inc_df[\"date\"] = dates_assimilation\n",
    "\n",
    "beta_baseline_df  = create_df_response(param_post_time[0,:], time=num_steps).reset_index();      beta_baseline_df[\"date\"]  = dates_assimilation\n",
    "beta_forcing_df   = create_df_response(param_post_time[1,:], time=num_steps).reset_index();      beta_forcing_df[\"date\"]  = dates_assimilation\n",
    "\n",
    "beta_time         = beta_value(np.arange(param_post_time.shape[-1]), amplitude=param_post_time[1,:], baseline=param_post_time[0, :].mean(0), phi=-1, period=best_period)\n",
    "\n",
    "beta_df           = create_df_response(beta_time, time=num_steps).reset_index();               beta_df[\"date\"]  = dates_assimilation\n",
    "theta_df          = create_df_response(param_post_time[2,:], time=num_steps).reset_index();      theta_df[\"date\"] = dates_assimilation\n",
    "obs_df            = create_df_response(np.squeeze(obs_post_time), time=num_steps).reset_index(); obs_df[\"date\"] = dates_assimilation\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(4, 1, figsize=(12.5, 12), sharex=True)\n",
    "\n",
    "ax[0].plot(beta_baseline_df.date, beta_baseline_df[\"mean\"], color=\"k\", lw=2, label=\"Mean\")\n",
    "ax[0].fill_between(beta_baseline_df.date, beta_baseline_df[\"low_95\"], beta_baseline_df[\"up_95\"], color=\"royalblue\", alpha=0.3, label=\"95% CI\"); ax[0].plot(beta_baseline_df.date, beta_baseline_df[\"up_95\"], color=\"gray\", lw=0.5); ax[0].plot(beta_baseline_df.date, beta_baseline_df[\"low_95\"], color=\"gray\", lw=0.5)\n",
    "ax[0].fill_between(beta_baseline_df.date, beta_baseline_df[\"low_50\"], beta_baseline_df[\"up_50\"], color=\"royalblue\", alpha=0.5, label=\"50% CI\"); ax[0].plot(beta_baseline_df.date, beta_baseline_df[\"up_50\"], color=\"gray\", lw=0.5); ax[0].plot(beta_baseline_df.date, beta_baseline_df[\"low_50\"], color=\"gray\", lw=0.5)\n",
    "\n",
    "\n",
    "ax[1].plot(beta_forcing_df.date, beta_forcing_df[\"mean\"], color=\"k\", lw=2, label=\"Mean\")\n",
    "ax[1].fill_between(beta_forcing_df.date, beta_forcing_df[\"low_95\"], beta_forcing_df[\"up_95\"], color=\"royalblue\", alpha=0.3, label=\"95% CI\"); ax[1].plot(beta_forcing_df.date, beta_forcing_df[\"up_95\"], color=\"gray\", lw=0.5); ax[1].plot(beta_forcing_df.date, beta_forcing_df[\"low_95\"], color=\"gray\", lw=0.5)\n",
    "ax[1].fill_between(beta_forcing_df.date, beta_forcing_df[\"low_50\"], beta_forcing_df[\"up_50\"], color=\"royalblue\", alpha=0.5, label=\"50% CI\"); ax[1].plot(beta_forcing_df.date, beta_forcing_df[\"up_50\"], color=\"gray\", lw=0.5); ax[1].plot(beta_forcing_df.date, beta_forcing_df[\"low_50\"], color=\"gray\", lw=0.5)\n",
    "\n",
    "\n",
    "ax[2].plot(beta_df.date, beta_df[\"mean\"], color=\"k\", lw=2, label=\"Mean\")\n",
    "ax[2].fill_between(beta_df.date, beta_df[\"low_95\"], beta_df[\"up_95\"], color=\"royalblue\", alpha=0.3, label=\"95% CI\"); ax[2].plot(beta_df.date, beta_df[\"up_95\"], color=\"gray\", lw=0.5); ax[2].plot(beta_df.date, beta_df[\"low_95\"], color=\"gray\", lw=0.5)\n",
    "ax[2].fill_between(beta_df.date, beta_df[\"low_50\"], beta_df[\"up_50\"], color=\"royalblue\", alpha=0.5, label=\"50% CI\"); ax[2].plot(beta_df.date, beta_df[\"up_50\"], color=\"gray\", lw=0.5); ax[2].plot(beta_df.date, beta_df[\"low_50\"], color=\"gray\", lw=0.5)\n",
    "\n",
    "ax[3].plot(theta_df.date, theta_df[\"mean\"], color=\"k\", lw=2, label=\"Mean\")\n",
    "ax[3].fill_between(theta_df.date, theta_df[\"low_95\"], theta_df[\"up_95\"], color=\"royalblue\", alpha=0.3, label=\"95% CI\"); ax[3].plot(theta_df.date, theta_df[\"up_95\"], color=\"gray\", lw=0.5); ax[3].plot(theta_df.date, theta_df[\"low_95\"], color=\"gray\", lw=0.5)\n",
    "ax[3].fill_between(theta_df.date, theta_df[\"low_50\"], theta_df[\"up_50\"], color=\"royalblue\", alpha=0.5, label=\"50% CI\"); ax[3].plot(theta_df.date, theta_df[\"up_50\"], color=\"gray\", lw=0.5); ax[3].plot(theta_df.date, theta_df[\"low_50\"], color=\"gray\", lw=0.5)\n",
    "\n",
    "\n",
    "ax[0].set_ylabel(r\"$\\omega$\")\n",
    "ax[1].set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "ax[2].set_ylabel(r\"$\\beta_t$\")\n",
    "ax[3].set_ylabel(r\"$\\theta$\")\n",
    "\n",
    "ax[-1].set_xlabel(\"Date [Month]\")\n",
    "#ax[2].text(theta_df.date.iloc[8],  βmax - (βmax-βmin), r'Population level contact rate', fontweight=\"bold\", fontsize=18)\n",
    "#ax[3].text(theta_df.date.iloc[8],  θmax - (θmax-θmin)/4, r'Likelihood of infection given carriage', fontweight=\"bold\", fontsize=18)\n",
    "\n",
    "for axi in ax.flatten():\n",
    "\n",
    "    axi.tick_params(which='both', axis='x', labelrotation=60, labelsize=15)\n",
    "    axi.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    axi.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    axi.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    axi.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(results_dir, \"figures\", \"model2\", \"eakf_params_posterior.png\"), dpi=300, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18.5, 12))\n",
    "\n",
    "ax1 = plt.subplot(231)\n",
    "ax2 = plt.subplot(232)\n",
    "ax3 = plt.subplot(233)\n",
    "ax4 = plt.subplot(212)\n",
    "\n",
    "ax1.plot(S_df.date,         S_df[\"mean\"]   / population, color=\"k\", lw=2, label=\"Susceptible  (S).\")\n",
    "ax1.fill_between(S_df.date, S_df[\"low_50\"] / population, S_df[\"up_50\"] / population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "ax1.fill_between(S_df.date, S_df[\"low_95\"] / population, S_df[\"up_95\"] / population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "ax1.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "ax2.plot(C_df.date,         C_df[\"mean\"] / population, color=\"k\", lw=2, label=\"Carriers (C)\")\n",
    "ax2.fill_between(C_df.date, C_df[\"low_50\"] / population, C_df[\"up_50\"] / population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "ax2.fill_between(C_df.date, C_df[\"low_95\"] / population, C_df[\"up_95\"] / population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "\n",
    "ax2.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "ax3.plot(I_df.date, I_df[\"mean\"]/population, color=\"k\", lw=2, label=\"Infected (I)\")\n",
    "ax3.fill_between(I_df.date, I_df[\"low_50\"]/population, I_df[\"up_50\"]/population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "ax3.fill_between(I_df.date, I_df[\"low_95\"]/population, I_df[\"up_95\"]/population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "\n",
    "ax3.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "\n",
    "ax4.plot(inc_df.date, inc_df[\"median\"],                          color=\"teal\", lw=2, label=\"Median\")\n",
    "ax4.fill_between(inc_df.date, inc_df[\"low_50\"], inc_df[\"up_50\"], color=\"teal\", alpha=0.5, label=\"50% CI\")\n",
    "ax4.fill_between(inc_df.date, inc_df[\"low_95\"], inc_df[\"up_95\"], color=\"teal\", alpha=0.3, label=\"95% CI\")\n",
    "\n",
    "ax4.scatter(data_assimilation_df.index.values, data_assimilation_df[\"confirmed\"], ec=\"red\", fc=\"red\", s=80, label=\"Observations\")\n",
    "ax4.plot(data_assimilation_df.index.values, data_assimilation_df[\"confirmed\"], linestyle=\"-\", color=\"red\", lw=2)\n",
    "\n",
    "ax4.set_ylabel(\"Reported IMD cases\")\n",
    "\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax3.legend(loc=\"upper right\")\n",
    "\n",
    "for axi in [ax1, ax2, ax3]:\n",
    "    axi.tick_params(which='both', axis='x', labelrotation=70, labelsize=15)\n",
    "    axi.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    axi.xaxis.set_minor_locator(mdates.YearLocator())\n",
    "\n",
    "ax4.tick_params(which='both', axis='both', labelrotation=60, labelsize=15)\n",
    "ax4.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n",
    "ax4.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax4.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax4.set_xlabel(\"Date [Month]\")\n",
    "ax4.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(results_dir, \"figures\", \"model2\", \"eakf_vars_posterior.png\"), dpi=300, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pop   = 200e6\n",
    "\n",
    "# Simulate with MLE\n",
    "S0     = np.squeeze(pop * sample_params_uniform(state_params_range, num_ensembles=num_ensembles))\n",
    "C0     = np.squeeze((1 - sample_params_uniform(state_params_range, num_ensembles=num_ensembles))*pop)\n",
    "I0     = np.zeros(( num_ensembles))\n",
    "inc    = np.zeros(( num_ensembles))\n",
    "x0     = np.array([S0, C0, I0, inc]) # array with initial conditions [num_state_variables, num_age_groups]\n",
    "x      = x0\n",
    "\n",
    "x_time = np.full((num_variables, num_ensembles, len(dates_assimilation)+1), np.nan)\n",
    "x_time[:,:,0] = x\n",
    "\n",
    "for idx_t, date in enumerate(dates_assimilation):\n",
    "\n",
    "    omega            = param_post_time[0, :, idx_t ].copy()\n",
    "    betas_amplitude  = param_post_time[1, :, idx_t ].copy()\n",
    "    betas  = beta_value(idx_t, amplitude=betas_amplitude, baseline=betas_amplitude.mean(), phi=-1, period=best_period)\n",
    "    thetas = param_post_time[2, :, idx_t]\n",
    "\n",
    "    # Integrate model\n",
    "    x_time[:, :, idx_t+1] = imd_model(np.minimum(x_time[:,:,idx_t], pop), betas, omega, thetas, N=pop, dt=30)\n",
    "\n",
    "\n",
    "S_post   = x_time[0, :, 1:]; S_df = create_df_response(S_post, time= num_steps);     S_df[\"date\"] = dates_assimilation\n",
    "C_post   = x_time[1, :, 1:]; C_df = create_df_response(C_post, time= num_steps);     C_df[\"date\"] = dates_assimilation\n",
    "I_post   = x_time[2, :, 1:]; I_df = create_df_response(I_post, time= num_steps);     I_df[\"date\"] = dates_assimilation\n",
    "inc_post = x_time[3, :, 1:]; inc_df = create_df_response(inc_post, time= num_steps); inc_df[\"date\"] = dates_assimilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18.5, 12))\n",
    "\n",
    "ax1 = plt.subplot(231)\n",
    "ax2 = plt.subplot(232)\n",
    "ax3 = plt.subplot(233)\n",
    "ax4 = plt.subplot(212)\n",
    "\n",
    "ax1.plot(S_df.date,         S_df[\"mean\"]   / population, color=\"k\", lw=2, label=\"Susceptible  (S).\")\n",
    "ax1.fill_between(S_df.date, S_df[\"low_95\"] / population, S_df[\"up_95\"] / population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "ax1.fill_between(S_df.date, S_df[\"low_50\"] / population, S_df[\"up_50\"] / population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "#ax1.set_ylim([0, 0.25])\n",
    "ax1.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "ax2.plot(C_df.date,         C_df[\"mean\"] / population, color=\"k\", lw=2, label=\"Carriers (C)\")\n",
    "ax2.fill_between(C_df.date, C_df[\"low_95\"] / population, C_df[\"up_95\"] / population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "ax2.fill_between(C_df.date, C_df[\"low_50\"] / population, C_df[\"up_50\"] / population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "ax2.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "ax3.plot(I_df.date, I_df[\"mean\"]/population, color=\"k\", lw=2, label=\"Infected (I)\")\n",
    "ax3.fill_between(I_df.date, I_df[\"low_95\"]/population, I_df[\"up_95\"]/population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "ax3.fill_between(I_df.date, I_df[\"low_50\"]/population, I_df[\"up_50\"]/population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "ax3.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "\n",
    "ax4.plot(inc_df.date, inc_df[\"mean\"], color=\"k\", lw=2, label=\"Model Incidence\")\n",
    "ax4.fill_between(inc_df.date, inc_df[\"low_95\"], inc_df[\"up_95\"], color=\"salmon\", alpha=0.3, label=\"95% CI\")\n",
    "ax4.fill_between(inc_df.date, inc_df[\"low_50\"], inc_df[\"up_50\"], color=\"salmon\", alpha=0.5, label=\"50% CI\")\n",
    "ax4.scatter(data_assimilation_df.index.values, data_assimilation_df[\"confirmed\"], ec=\"white\", fc=\"red\", s=80, label=\"Observations\")\n",
    "ax4.plot(data_assimilation_df.index.values, data_assimilation_df[\"confirmed\"], linestyle=\"--\", color=\"k\")\n",
    "\n",
    "ax4.set_ylabel(\"Reported IMD cases\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "\n",
    "for axi in [ax1, ax2, ax3]:\n",
    "    axi.tick_params(which='both', axis='x', labelrotation=70, labelsize=15)\n",
    "    axi.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    axi.xaxis.set_minor_locator(mdates.YearLocator())\n",
    "\n",
    "ax4.tick_params(which='both', axis='both', labelrotation=60, labelsize=15)\n",
    "ax4.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n",
    "ax4.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax4.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax4.set_xlabel(\"Date [Month]\")\n",
    "ax4.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(results_dir, \"figures\", \"model2\", \"eakf_freesim.png\"), dpi=300, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_cooling(num_iteration_if, cooling_factor=0.9):\n",
    "    alphas = cooling_factor**np.arange(num_iteration_if)\n",
    "    return alphas**2\n",
    "\n",
    "def hyperbolic_cooling(num_iteration_if, cooling_factor=0.9):\n",
    "    alphas = 1/(1+cooling_factor*np.arange(num_iteration_if))\n",
    "    return alphas\n",
    "\n",
    "def cooling(num_iteration_if, type_cool=\"geometric\", cooling_factor=0.9):\n",
    "    if type_cool==\"geometric\":\n",
    "        return geometric_cooling(num_iteration_if, cooling_factor=cooling_factor)\n",
    "    elif type_cool==\"hyperbolic\":\n",
    "        return hyperbolic_cooling(num_iteration_if, cooling_factor=cooling_factor)\n",
    "\n",
    "def random_walk_perturbation(param, param_std, num_params, num_ensembles):\n",
    "    return param + param_std * np.random.normal(size=(num_params, num_ensembles))\n",
    "\n",
    "def inflate_ensembles(ens, inflation_value=1.2, num_ensembles=300):\n",
    "    return np.mean(ens,1, keepdims=True)*np.ones((1,num_ensembles)) + inflation_value*(ens-np.mean(ens,1, keepdims=True)*np.ones((1,num_ensembles)))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def IF2_eakf(imd_model, obs_df, forcing, param_prior_dict, if2_settings, pop=1e6, perturb_time=True):\n",
    "\n",
    "    cooling_factor   = cooling(if2_settings[\"num_iters_mif\"], type_cool=if2_settings[\"type_cooling\"], cooling_factor=if2_settings[\"alpha_mif\"])\n",
    "\n",
    "    param_range      = np.array([v for k, v in param_prior_dict.items()])\n",
    "    std_param        = param_range[:,1]-param_range[:,0]\n",
    "    SIG              = std_param ** 2 / 4; #  initial covariance of parameters\n",
    "\n",
    "    perturbation     = np.array([std_param % list(np.round(std_param)+0.1)]).T\n",
    "\n",
    "    num_steps          = len(obs_df)\n",
    "\n",
    "    x_states_post_all  = np.full((if2_settings[\"num_state_vars\"],   if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan)   # Array to store state variables.\n",
    "    param_mean_iter    = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_iters_mif\"]+1), np.nan)                               # Array to store posterior parameters in iterations.\n",
    "    para_post_all      = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan)       # Array to store posterior parameters.\n",
    "    obs_post_all       = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "    param_iter         = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    dates_assimilation = if2_settings[\"dates_assimilation\"]\n",
    "    dates              = if2_settings[\"dates_simulation\"]\n",
    "    print(f\"Running MIF  \\n\")\n",
    "\n",
    "    for n in tqdm(range(if2_settings[\"num_iters_mif\"])):\n",
    "        if n==0:\n",
    "            p_prior               = sample_params_uniform(param_prior_dict, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "            S0     = np.squeeze(pop * sample_params_uniform(state_params_range, num_ensembles=num_ensembles))\n",
    "            C0     = np.squeeze((1 - sample_params_uniform(state_params_range, num_ensembles=num_ensembles))*pop)\n",
    "            I0     = np.random.uniform(1e-9, 0.01 / 100, num_ensembles )*pop\n",
    "\n",
    "            inc    = np.zeros(( num_ensembles ))\n",
    "            x0     = np.array([S0, C0, I0, inc]) # array with initial conditions [num_state_variables, num_age_groups]\n",
    "            x      = x0\n",
    "\n",
    "            param_mean_iter[:, n] = np.mean(p_prior, -1)\n",
    "\n",
    "        else:\n",
    "            params_mean     = param_mean_iter[:,n]\n",
    "            params_var      = SIG * cooling_factor[n]\n",
    "\n",
    "            p_prior         = sample_params_normal(param_prior_dict, params_mean, params_var, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            S0              = np.squeeze(pop * sample_params_uniform(state_params_range, num_ensembles=num_ensembles))\n",
    "            C0              = np.squeeze((1 - sample_params_uniform(state_params_range, num_ensembles=num_ensembles))*pop)\n",
    "            I0              = np.random.uniform(1e-9, 0.01 / 100, num_ensembles )*pop\n",
    "\n",
    "            inc    = np.zeros(( num_ensembles))\n",
    "            x0     = np.array([S0, C0, I0, inc]) # array with initial conditions [num_state_variables, num_age_groups]\n",
    "            x      = x0\n",
    "\n",
    "        param_post_time   = np.full((if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "        x_post_time       = np.full((if2_settings[\"num_state_vars\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "        obs_post_time     = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "        idx_date_update   = 0\n",
    "\n",
    "        confirmed_t = np.zeros((if2_settings[\"num_ensembles\"], 1))\n",
    "        for idx_t, date in enumerate(dates_assimilation):\n",
    "            # Integrate model\n",
    "            omega            = p_prior[0, :]\n",
    "            betas_amplitude  = p_prior[1, :]\n",
    "            thetas           = p_prior[2, :]\n",
    "\n",
    "            betas    = beta_value(idx_t, amplitude=betas_amplitude, baseline=omega, phi=-1, period=best_period)\n",
    "            x_ens    = imd_model(np.clip(x, 0, population), betas, 0, thetas, N=population, dt=30)\n",
    "            x        = x_ens\n",
    "            confirmed_t  +=  np.expand_dims(x[-1,:], -1)\n",
    "\n",
    "            # Inflate state variables\n",
    "            x = inflate_ensembles(x, inflation_value=if2_settings[\"lambda_inf\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            x = checkbound_state_vars(x_state_ens=x, pop=population)\n",
    "\n",
    "            if perturb_time:\n",
    "                # Transform parameters for perturbation\n",
    "                std_params = perturbation*cooling_factor[n]\n",
    "                p_prior    = random_walk_perturbation(p_prior, std_params, if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"])\n",
    "\n",
    "            # Inflate parameters\n",
    "            p_prior        = inflate_ensembles(p_prior, inflation_value=if2_settings[\"lambda_inf\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            p_prior        = checkbound_params(param_prior_dict, p_prior, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "            oev_confirmed_time = obs_df.loc[date][\"oev\"]\n",
    "            confirmed_time     = obs_df.loc[date][\"confirmed\"]\n",
    "\n",
    "            param_post = p_prior.copy()\n",
    "            x_prior    = x.copy()\n",
    "\n",
    "            x_post, param_post, confirmed_obs_post = eakf_step(x_prior, param_post, np.squeeze(confirmed_t), confirmed_time, oev_confirmed_time, param_prior_dict, num_var=4)\n",
    "            S            = x_post[0, :] # Susceptible  [1, num_ensembles]\n",
    "            C            = x_post[1, :] # Carriers     [1, num_ensembles]\n",
    "            I            = x_post[2, :] # Infected     [1, num_ensembles]\n",
    "            x_post[0, :] = pop*np.ones(S.shape) - C - I # re-adjust susceptibility\n",
    "\n",
    "            x_post                                 = checkbound_state_vars(x_state_ens=x_post, pop=pop)\n",
    "            param_post                             = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "            x       = x_post.copy()\n",
    "            p_prior = param_post.copy()\n",
    "\n",
    "            obs_post_time[:,:,idx_date_update]    = confirmed_obs_post\n",
    "            param_post_time[:,:,idx_date_update]  = param_post\n",
    "            x_post_time[:,:,idx_date_update]      = x_post\n",
    "\n",
    "            idx_date_update += 1\n",
    "\n",
    "            confirmed_t = np.zeros((if2_settings[\"num_ensembles\"], 1))\n",
    "\n",
    "        x_states_post_all  = x_post_time\n",
    "        obs_post_all[:,:,:,n]       = obs_post_time\n",
    "        para_post_all[:,:,:,n]      = param_post_time\n",
    "        param_iter[:,:,n]           = param_post_time.mean(-1)\n",
    "        param_mean_iter[:,n+1]      = param_post_time.mean(-1).mean(-1)\n",
    "\n",
    "    return x_states_post_all, obs_post_all, para_post_all, param_iter, param_mean_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_df = data_df.copy()\n",
    "this_df = data_df.copy().set_index(\"date\").resample(\"M\").sum().reset_index()\n",
    "\n",
    "this_df           = this_df.rename(columns={\"total\": \"confirmed\"})\n",
    "this_df[\"oev\"]    = compute_oev(this_df[\"confirmed\"].values)\n",
    "\n",
    "days_simulation       = list(pd.date_range(start=pd.to_datetime(\"2006-01-01\"), end=this_df.iloc[-1][\"date\"]))\n",
    "data_assimilation_df  = this_df.copy()\n",
    "data_assimilation_df  = data_assimilation_df.set_index(\"date\")\n",
    "dates_assimilation    = data_assimilation_df.index.values\n",
    "\n",
    "\n",
    "obs_df = this_df.copy().set_index(\"date\")\n",
    "\n",
    "dict_params_range[\"omega\"]             = [βmin, 0.01] #[βmin, βmax]\n",
    "dict_params_range[\"beta_amplitude\"]    = [βmin, βmax] #[(βmax-βmin)/100, (βmax-βmin)/10]\n",
    "dict_params_range[\"theta\"]             = [θmin, θmax]\n",
    "\n",
    "\n",
    "param_prior_dict = {}\n",
    "param_prior_dict[\"beta_baseline\"]     = [βmin, 0.01]\n",
    "param_prior_dict[\"beta_amplitude\"]    = [βmin, βmax] #[(βmax-βmin)/100, (βmax-βmin)/10]\n",
    "param_prior_dict[\"theta\"]             = [θmin, θmax]\n",
    "\n",
    "if2_settings = {}\n",
    "if2_settings[\"num_params\"]       = len(param_prior_dict)\n",
    "if2_settings[\"num_state_vars\"]   = 4\n",
    "if2_settings[\"num_observations\"] = 1\n",
    "if2_settings[\"lambda_inf\"]       = 1.01\n",
    "if2_settings[\"num_iters_mif\"]    = 80\n",
    "if2_settings[\"alpha_mif\"]        = 0.9 # Variance shrinking factor\n",
    "if2_settings[\"type_cooling\"]     = \"geometric\"\n",
    "if2_settings[\"num_ensembles\"]    = 300\n",
    "\n",
    "if2_settings[\"dates_assimilation\"] = dates_assimilation\n",
    "if2_settings[\"dates_simulation\"]   = days_simulation\n",
    "\n",
    "forcing = beta_computed_df.beta.values\n",
    "x_states_post_all, obs_post_all, para_post_all, param_iter, param_mean_iter = IF2_eakf(imd_model, obs_df, None, param_prior_dict, if2_settings, pop=200e6,  perturb_time=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_df = create_df_response(param_iter[0,:,:], time=if2_settings[\"num_iters_mif\"]).reset_index()\n",
    "beta_df  = create_df_response(param_iter[1,:,:], time=if2_settings[\"num_iters_mif\"]).reset_index()\n",
    "theta_df = create_df_response(param_iter[2,:,:], time=if2_settings[\"num_iters_mif\"]).reset_index()\n",
    "\n",
    "fig, ax  = plt.subplots(3, 1, figsize=(15.5, 7.2), sharex=True)\n",
    "\n",
    "ax[0].plot(range(if2_settings[\"num_iters_mif\"]), omega_df[\"mean\"], color=\"k\"); ax[0].fill_between(range(if2_settings[\"num_iters_mif\"]), omega_df[\"up_95\"], omega_df[\"low_95\"], color=\"k\", alpha=0.1);  ax[0].fill_between(range(if2_settings[\"num_iters_mif\"]), omega_df[\"up_50\"], omega_df[\"low_50\"], color=\"k\", alpha=0.2)\n",
    "ax[1].plot(range(if2_settings[\"num_iters_mif\"]), beta_df[\"mean\"], color=\"k\");  ax[1].fill_between(range(if2_settings[\"num_iters_mif\"]), beta_df[\"up_95\"], beta_df[\"low_95\"], color=\"k\", alpha=0.1);  ax[1].fill_between(range(if2_settings[\"num_iters_mif\"]), beta_df[\"up_50\"], beta_df[\"low_50\"], color=\"k\", alpha=0.2)\n",
    "ax[2].plot(range(if2_settings[\"num_iters_mif\"]), theta_df[\"mean\"], color=\"k\"); ax[2].fill_between(range(if2_settings[\"num_iters_mif\"]), (theta_df[\"up_95\"]), (theta_df[\"low_95\"]), color=\"k\", alpha=0.1); ax[2].fill_between(range(if2_settings[\"num_iters_mif\"]), theta_df[\"up_50\"], theta_df[\"low_50\"], color=\"k\", alpha=0.2)\n",
    "\n",
    "ax[0].set_ylabel(r\"$\\omega$\")\n",
    "ax[2].set_ylabel(r\"$\\theta$\")\n",
    "ax[1].set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "ax[-1].set_xlabel(\"IF Iteration\")\n",
    "\n",
    "#fig.savefig(os.path.join(results_dir, \"figures\", \"model2\", \"if-eakf_convergence.png\"), dpi=300, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_df          = pd.DataFrame(columns=[\"type\", \"beta\", \"theta\"])\n",
    "mle_df[\"type\"]  = [\"mean\", \"variance\"]\n",
    "mle_df[\"omega\"] = [param_iter[0,:,-1].mean(), param_iter[0,:,-1].var()]\n",
    "mle_df[\"beta\"]  = [param_iter[1,:,-1].mean(), param_iter[1,:,-1].var()]\n",
    "mle_df[\"theta\"] = [param_iter[2,:,-1].mean(), param_iter[2,:,-1].var()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pop   = 200e6\n",
    "dates = if2_settings[\"dates_simulation\"]\n",
    "\n",
    "# Simulate with MLE\n",
    "S0     = np.squeeze(pop * sample_params_uniform(state_params_range, num_ensembles=num_ensembles))\n",
    "C0     = np.squeeze((1 - sample_params_uniform(state_params_range, num_ensembles=num_ensembles))*pop)\n",
    "I0     = np.random.uniform(1e-9, 0.0001 / 100, num_ensembles )*pop\n",
    "\n",
    "inc    = np.zeros(( num_ensembles))\n",
    "x0     = np.array([S0, C0, I0, inc]) # array with initial conditions [num_state_variables, num_age_groups]\n",
    "x      = x0\n",
    "\n",
    "\n",
    "beta_base       = np.ones((num_ensembles)) * mle_df[mle_df.type==\"mean\"][\"omega\"].values[0]\n",
    "beta_amp        = np.ones((num_ensembles)) * mle_df[mle_df.type==\"mean\"][\"beta\"].values[0]\n",
    "thetas          = np.ones((num_ensembles)) * mle_df[mle_df.type==\"mean\"][\"theta\"].values[0]\n",
    "\n",
    "x_time        = np.full((num_variables, num_ensembles, len(dates_assimilation)+1), np.nan)\n",
    "x_time[:,:,0] = x\n",
    "\n",
    "for idx_t, date in enumerate(dates_assimilation):\n",
    "    betas_forcing         =  beta_value(idx_t, amplitude=beta_amp, phi=-1, period=best_period, baseline=beta_base)\n",
    "    x_time[:, :, idx_t+1] = imd_model(x_time[:,:,idx_t], betas_forcing, 0, thetas, N=population, dt=30)\n",
    "\n",
    "S   = x_time[0, :, 1:];  S_df = create_df_response(S, time= num_steps);       S_df[\"date\"] = dates_assimilation\n",
    "C   = x_time[1, :, 1:];  C_df = create_df_response(C, time= num_steps);       C_df[\"date\"] = dates_assimilation\n",
    "I   = x_time[2, :, 1:];  I_df = create_df_response(I, time= num_steps);       I_df[\"date\"] = dates_assimilation\n",
    "inc = x_time[3, :, 1:];  inc_df = create_df_response(inc, time= num_steps);   inc_df[\"date\"] = dates_assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18.5, 12))\n",
    "\n",
    "ax1 = plt.subplot(231)\n",
    "ax2 = plt.subplot(232)\n",
    "ax3 = plt.subplot(233)\n",
    "ax4 = plt.subplot(212)\n",
    "\n",
    "ax1.plot(S_df.date,         S_df[\"mean\"]   / population, color=\"k\", lw=2, label=\"Susceptible  (S).\")\n",
    "ax1.fill_between(S_df.date, S_df[\"low_95\"] / population, S_df[\"up_95\"] / population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "ax1.fill_between(S_df.date, S_df[\"low_50\"] / population, S_df[\"up_50\"] / population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "#ax1.set_ylim([0, 0.25])\n",
    "ax1.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "ax2.plot(C_df.date,         C_df[\"mean\"] / population, color=\"k\", lw=2, label=\"Carriers (C)\")\n",
    "ax2.fill_between(C_df.date, C_df[\"low_95\"] / population, C_df[\"up_95\"] / population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "ax2.fill_between(C_df.date, C_df[\"low_50\"] / population, C_df[\"up_50\"] / population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "ax2.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "ax3.plot(I_df.date, I_df[\"mean\"]/population, color=\"k\", lw=2, label=\"Infected (I)\")\n",
    "ax3.fill_between(I_df.date, I_df[\"low_95\"]/population, I_df[\"up_95\"]/population, color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "ax3.fill_between(I_df.date, I_df[\"low_50\"]/population, I_df[\"up_50\"]/population, color=\"gray\", alpha=0.5, label=\"50% CI\")\n",
    "ax3.set_ylabel(\"Pop. Fraction\")\n",
    "\n",
    "ax4.plot(inc_df.date, inc_df[\"mean\"], color=\"k\", lw=2, label=\"Model Incidence\")\n",
    "ax4.fill_between(inc_df.date, inc_df[\"low_95\"], inc_df[\"up_95\"], color=\"salmon\", alpha=0.3, label=\"95% CI\")\n",
    "ax4.fill_between(inc_df.date, inc_df[\"low_50\"], inc_df[\"up_50\"], color=\"salmon\", alpha=0.5, label=\"50% CI\")\n",
    "ax4.scatter(data_assimilation_df.index.values, data_assimilation_df[\"confirmed\"], ec=\"white\", fc=\"red\", s=80, label=\"Observations\")\n",
    "ax4.plot(data_assimilation_df.index.values, data_assimilation_df[\"confirmed\"], linestyle=\"--\", color=\"k\")\n",
    "\n",
    "ax4.set_ylabel(\"Reported IMD cases\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "\n",
    "for axi in [ax1, ax2, ax3]:\n",
    "    axi.tick_params(which='both', axis='x', labelrotation=70, labelsize=15)\n",
    "    axi.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    axi.xaxis.set_minor_locator(mdates.YearLocator())\n",
    "\n",
    "ax4.tick_params(which='both', axis='both', labelrotation=60, labelsize=15)\n",
    "ax4.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n",
    "ax4.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax4.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax4.set_xlabel(\"Date [Month]\")\n",
    "ax4.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "#fig.savefig(os.path.join(results_dir, \"figures\", \"model2\", \"if-eakf_MLESim.png\"), dpi=300, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_eakf(data_df, forecast_horizon=6):\n",
    "\n",
    "        data_assimilation_df  = data_df.copy()\n",
    "        data_assimilation_df  = data_assimilation_df.set_index(\"date\").drop_duplicates()\n",
    "        dates_assimilation    = data_assimilation_df.index.values\n",
    "\n",
    "        idx_date_update = 0\n",
    "\n",
    "        dict_params_range = {}\n",
    "        dict_params_range[\"beta_baseline\"]     = [βmin, 0.01]\n",
    "        dict_params_range[\"beta_amplitude\"]    = [βmin, βmax] #[(βmax-βmin)/100, (βmax-βmin)/10]\n",
    "        dict_params_range[\"theta\"]             = [θmin, θmax]\n",
    "\n",
    "        state_params_range       = {}\n",
    "        state_params_range[\"S0\"] = [75/100, 95/100]\n",
    "\n",
    "\n",
    "        param_prior = sample_params_uniform(dict_params_range, num_ensembles=num_ensembles)\n",
    "\n",
    "        obs_t = np.zeros((num_ensembles))\n",
    "\n",
    "        num_params    = 3\n",
    "        num_variables = 4\n",
    "\n",
    "        num_steps        = len(data_assimilation_df)\n",
    "        param_post_time  = np.zeros((num_params, num_ensembles,    num_steps))\n",
    "        x_post_time      = np.zeros((num_variables, num_ensembles, num_steps))\n",
    "        obs_post_time    = np.zeros((1, num_ensembles, num_steps))\n",
    "\n",
    "\n",
    "        idx_date_update   = 0\n",
    "\n",
    "        obs_t         = np.zeros((num_ensembles))\n",
    "\n",
    "        S0     = np.squeeze(population * sample_params_uniform(state_params_range, num_ensembles=num_ensembles))\n",
    "        C0     = np.squeeze((1 - sample_params_uniform(state_params_range, num_ensembles=num_ensembles))*population)\n",
    "        I0     = np.zeros(( num_ensembles))\n",
    "\n",
    "        inc    = np.zeros(( num_ensembles))\n",
    "        x0     = np.array([S0, C0, I0, inc]) # array with initial conditions [num_state_variables, num_age_groups]\n",
    "        x      = x0\n",
    "\n",
    "\n",
    "        #param_prior[1, :] = np.ones(num_ensembles) * 1e-3\n",
    "        x_prior = np.zeros((num_variables, num_ensembles))\n",
    "\n",
    "        for idx_date, date in tqdm(enumerate(dates_assimilation)):\n",
    "\n",
    "                # Integrate model\n",
    "                omega            = param_prior[0, :]\n",
    "                betas_amplitude  = param_prior[1, :]\n",
    "                thetas           = param_prior[2, :]\n",
    "\n",
    "                betas      = beta_value(idx_date, amplitude=betas_amplitude, baseline=omega, phi=-1, period=best_period)    #beta_baseline*(1+ betas_amplitude * forcing[idx_t])\n",
    "                x_prior    = imd_model(np.clip(x, 0, population), betas, 0, thetas, N=population, dt=30)\n",
    "\n",
    "                x          = x_prior.copy()\n",
    "                obs        = x[-1,:]\n",
    "                obs_t      += obs\n",
    "\n",
    "                # Since the age groups are an index, the arrangement of the age groups remains.\n",
    "                oev_confirmed_time = data_assimilation_df.loc[date][\"oev\"]\n",
    "                confirmed_time     = data_assimilation_df.loc[date][\"confirmed\"]\n",
    "\n",
    "                x_post, param_post, obs_post = eakf_step(x_prior, param_prior, obs_t, confirmed_time, oev_confirmed_time, dict_params_range, num_var=4)\n",
    "                S       = x_post[0, :] # Susceptible  [1, num_ensembles]\n",
    "                C       = x_post[1, :] # Carriers     [1, num_ensembles]\n",
    "                I       = x_post[2, :] # Infected     [1, num_ensembles]\n",
    "                x_post[0, :] = population*np.ones(S.shape) - C - I # re-adjust susceptibility\n",
    "\n",
    "                x_post                       = checkbound_state_vars(x_post, population)\n",
    "                param_post                   = checkbound_params(dict_params_range, param_post, num_ensembles=300)\n",
    "\n",
    "                x = x_post.copy()\n",
    "\n",
    "                # Use posterior and next prior\n",
    "                param_prior  = param_post.copy()\n",
    "\n",
    "                obs_post_time[:,:,idx_date_update]      = obs_post\n",
    "                param_post_time[:,:,idx_date_update]     = param_prior\n",
    "                x_post_time[:,:,idx_date_update]         = x_post\n",
    "\n",
    "                idx_date_update += 1\n",
    "\n",
    "                obs_t           = np.zeros((num_ensembles))\n",
    "\n",
    "\n",
    "        # Integrate model\n",
    "        omega            = param_post_time[0, :, -1]\n",
    "        betas_amplitude  = param_post_time[1, :, -1]\n",
    "        theta            = param_post_time[2, :, -1]\n",
    "\n",
    "        x_forecast = np.full((forecast_horizon+1, num_variables, num_ensembles), np.nan)\n",
    "        x_forecast[0,:,:] = x\n",
    "\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "\n",
    "        dates_forecasts = pd.date_range(start=pd.to_datetime(dates_assimilation[-1])+ relativedelta(months=1), periods=forecast_horizon, freq=\"M\")\n",
    "\n",
    "        for idx_forecast, date_forecast in enumerate(range(forecast_horizon)):\n",
    "                betas                          = beta_value(idx_forecast, amplitude=betas_amplitude, baseline=omega, phi=-1, period=best_period)    #beta_baseline*(1+ betas_amplitude * forcing[idx_t])\n",
    "                x_forecast[idx_forecast+1,:,:] = imd_model(x_forecast[idx_forecast,:,:], betas, 0, theta, N=population, dt=30)\n",
    "        forecast_df = create_df_response(x_forecast[1:, -1, :].T, time=forecast_horizon, quantiles=[5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 97.5]).reset_index(); forecast_df.date=dates_forecasts\n",
    "\n",
    "        return x_forecast, forecast_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_forecasts = obs_df.reset_index().date[11:].values\n",
    "date_init       = obs_df.reset_index().date.iloc[0]\n",
    "\n",
    "FORECAST_MONTHS = 6\n",
    "\n",
    "path_to_save_forecast = os.path.join(results_dir, \"forecast\", \"eakf_model2\")\n",
    "\n",
    "for idx, date in tqdm(enumerate(dates_forecasts)):\n",
    "\n",
    "    ts = pd.to_datetime(str(date))\n",
    "    d = ts.strftime('%Y-%m-%d')\n",
    "\n",
    "    usa_df          = obs_df.reset_index()\n",
    "    dates_use       = pd.date_range(start=date_init, end=date, freq=\"M\")\n",
    "    fit_data        = usa_df[usa_df.date.isin((list(dates_use)))]\n",
    "\n",
    "    _, forecast_df = forecast_eakf(fit_data, forecast_horizon=FORECAST_MONTHS+1)\n",
    "    forecast_df[\"forecast_date\"] = date\n",
    "    forecast_df[\"add\"] = 0\n",
    "\n",
    "    forecast_df.to_csv(os.path.join(path_to_save_forecast, f\"{d}.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
